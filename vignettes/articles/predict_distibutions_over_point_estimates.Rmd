---
title: "Predict Distibutions over Point Estimate"
bibliography: [../../inst/REFERENCES.bib]
biblio-style: apalike
link-citations: yes
editor_options: 
  markdown: 
    wrap: 80
---

<!-- Compress random variables into distribution objects -->

```{r, include = FALSE}
source(file.path(usethis::proj_get(), "vignettes",  "_common.R"))
```

## Motivation?

The ability to make correct inference on a random variable is influence by the
variable size. As the variable size gets bigger, our ability to make actionable
inference increases. For example, measuring people hight and taking the 95 hight
quantile allows automotive designers to decide on the space required between the
car seat and its ceiling.

Increasing random variable sizes requires us to devise a strategy for how to
represent them for further analysis, especially, in the case of multiple random
variable. For example, say we investigate the relationship of cars'
specifications and their fuel consumption. We start by taking *Mazda RX4* for a
ride, and measuring how many miles it covers before it consumes one gallon out
its 17 gallon fuel tank. The measurement could look something like this:

```{r, echo=TRUE}
Mazda_RX4 = c(22, 24, 18, 22, 18, 29, 26, 25, 23, 21, 22, 22, 17, 21, 19, 20, 24)
```

We do the same for the *Datsun 710* 12 gallon fuel tank:

```{r, echo=TRUE}
Datsun_710 = c(29, 27, 24, 26, 24, 23, 21, 25, 17, 18, 22, 25)
```

The question then is how to represent the two cars MPG in adjacent to their
following specifications:

```{r, results='hide'}
(
    cars_specs <- mtcars 
    %>% dplyr::select(-mpg) 
    %>% tibble::rownames_to_column("model")
    %>% dplyr::filter(model %in% c("Mazda RX4", "Datsun 710"))
)
```

```{r, echo=TRUE}
print(cars_specs)
```


There are two common ways:

1. Convert each random vector into a point estimator, such as median:

```{r, echo = TRUE}
cars <- data.frame(mpg = c(median(Mazda_RX4), median(Datsun_710)), cars_specs)
print(cars)
```

2. Add an `mpg` column, where each cell is a list contain all the information
available for a particular car

```{r, echo = TRUE}
cars <- data.frame(mpg = I(list(Mazda_RX4, Datsun_710)), cars_specs)
print(cars)
```

While representing both the 'mpg' measurements and the cars' specification in a
table is convenient for further analysis, there are some drawbacks to consider:

1. The first approach, which is also the most common one, exhibits information
loss when the variable is compressed into a scalar. As a result of the
information loss, there is no way to calculate other important statistics such
as the interquartile range (IQR) or mean.

2. The second approach can be memory/computational prohibitive, especially as
the number of samples in the random vector increases.

This article suggests a third approach that keeps important information and
bounds the size of information representation, regardless of the sample size.
This approach is based on statistical distributions.

## Working with Distribution Objects

### What is a distribution object?

A **distribution object** preserves important statistical qualities of a random
variable in a succinct manner. Using the
[`distributional`](https://cran.r-project.org/web/packages/distributional/index.html)
R package, we can compress the following vector

```{r, echo=TRUE}
mpg_vec <- c(29, 27, 24, 26, 24, 23, 21, 25, 17, 18, 22, 25)
print(mpg_vec)
```

into a **distribution object** on length 1

```{r, echo=TRUE}
mpg_dist <- distributional::dist_normal(mu = mean(mpg_vec), sigma = sd(mpg_vec))
print(mpg_dist)
```

```{r, warning=TRUE}
warning("By using the normal distribution, a random variable of **any length** can be summarised by **two parameters**, the sample mean and standard deviation.")
```


A **distribution object** allows us to move a from `data.frame` with point
estimate column into a `data.frame` with a distribution column. For example,
instead of compressing the 'mpg' measurements of each car in the 'mtcars'
dataset into point estimations (the sample mean)

```{r, echo=FALSE}
data(mtcars, package = "datasets")
(
  mtcars
  %>% tibble::rownames_to_column("model")
  %>% tibble::as_tibble() 
  %>% dplyr::slice(c(1,3)) 
)
```

We can capture more information about the *mpg* measurements by using
**distribution objects**

```{r, echo=FALSE}
set.seed(1104)
(
  mtcars
  %>% tibble::rownames_to_column("model")
  %>% dplyr::rowwise() 
  %>% dplyr::mutate(mpg = distributional::dist_normal(mpg, round(runif(1, 1,3),1)))
  %>% dplyr::ungroup()
  %>% dplyr::slice(c(1,3))
)
```


### What operations can we perform on a distribution object?

Firstly, you can easily move from a **distribution object** into a point estimate by
using `distributional` functions:

```{r, echo=TRUE}
mpg_vec <- c(29, 27, 24, 26, 24, 23, 21, 25, 17, 18, 22, 25)
mpg_dist <- distributional::dist_normal(mu = mean(mpg_vec), sigma = sd(mpg_vec))

mean(mpg_vec); mean(mpg_dist)
median(mpg_vec); median(mpg_dist)
var(mpg_vec); distributional::variance(mpg_dist)

quantile(mpg_vec, p=0.75)[[1]]; quantile(mpg_dist, p=0.75)
min(mpg_vec); quantile(mpg_dist, p=0.01) # min approximation
max(mpg_vec); quantile(mpg_dist, p=0.99) # max approximation
```

Second, you can easily move from a **distribution object** into *Confidence Intervals* by using `distributional::hilo`:

```{r, echo=TRUE}
# z-confidence interval
c(
  mean(mpg_vec) - 1.96 * sd(mpg_vec)/sqrt(length(mpg_vec)),
  mean(mpg_vec) + 1.96 * sd(mpg_vec)/sqrt(length(mpg_vec))
) %>% round()

# quantile confidence interval
quantile(mpg_vec, probs = c(0.025, 0.975)) %>% round()

# distributional employs quantile confidence interval rather than z-confidence interval
distributional::hilo(mpg_dist, size = 95) %>% round()
```

```{r, warning=TRUE}
warning("Use `distributional::new_hilo` if you need a different type of confidence interval")
```

```{r}
z_ci <- distributional::new_hilo(
  lower = mean(mpg_vec) - 1.96 * sd(mpg_vec)/sqrt(length(mpg_vec)),
  upper = mean(mpg_vec) + 1.96 * sd(mpg_vec)/sqrt(length(mpg_vec)),
  size = 95
)

print(z_ci)
```

Finally, you can work with **distribution objects** stored in a data.frame as
you would do with any other atomic type:

```{r, echo=TRUE}
# Generate a data.frame with distribution objects
cars <- data.frame(
  model = c("Mazda RX4", "Datsun 710"),
  mpg = c(distributional::dist_normal(21, 2), distributional::dist_normal(22.8, 3))
)

# Extracting 'mpg' mean point estimation
cars %>% 
  dplyr::mutate(mpg = mean(mpg))

# Extracting 'mpg' 95% confidence interval
cars %>% 
  dplyr::mutate(CI = distributional::hilo(mpg, 95)) %>% 
  dplyr::mutate(CI_LB = CI$lower, CI_UB = CI$upper) %>% 
  dplyr::select(-CI)
```

```{r, message=TRUE}
message("See all available operations at [`distributional` package site](https://pkg.mitchelloharawild.com/distributional/).")
```


## Generating Distribution Objects

### Generating a distribution from point estimation

Compressing a random variable into a point estimation entails information loss.
It is not possible to restore the original distribution of a random variable
without prior information. Yet `distributional::dist_degenerate` allows us to
cast the point estimation into a **distribution object**.

For example, representing the 'mpg' column within the 'mtcars' dataset can be
achieved by a combination of `dplyr::mutate` and
`distributional::dist_degenerate`:
```{r, echo=TRUE}
mtcars %>% 
  tibble::as_tibble(rownames = "model") %>% 
  dplyr::mutate(mpg = distributional::dist_degenerate(mpg)) %>% 
  head(3)
```

### Generating a distribution from bootstrap sampling

Steps:

1. Define functions for model fitting and model prediction;
2. Perform bootstrap sampling on the data;
3. Compress the data with **distribution objects**; and
4. Bind the **distribution objects** with the rest of the data.

```{r, echo=TRUE, cache=TRUE}
# Helpers 
fit_model <- function(split)
    lm(formula = mpg ~ ., data = rsample::analysis(split)) 

predict_model <- function(split, mdl)
    predict(object = mdl, newdata = rsample::assessment(split))

# Generate a distribution for mpg via linear regression and bootstrap sampling
set.seed(1623)

sampler <- rsample::bootstraps(mtcars, times = 200)

sampler$mdl <- purrr::map(sampler$splits, fit_model)

sampler$fit <- purrr::map2(sampler$splits, sampler$mdl, predict_model)

(
  mpg_distribution <- sampler$fit
  %>% dplyr::bind_rows()
  %>% tidyr::pivot_longer(dplyr::everything())  
  %>% tidyr::drop_na(value) 
  %>% dplyr::rename(model = name) 
  %>% dplyr::group_by(model)  
  %>% dplyr::summarise(
    mpg = distributional::dist_normal(mu = mean(value), sigma = sd(value))
  )
)

# Bind mpg distribution objects with cars specification
(
  dplyr::left_join(
    tibble::as_tibble(mtcars, rownames = "model") %>% dplyr::select(-mpg),
    mpg_distribution
  ) 
  %>% dplyr::select(model, mpg, dplyr::everything()) 
  %>% head(3)
)
```



<!-- lm predict se.fit = FALSE -->

<!-- lm predict se.fit = TRUE -->
