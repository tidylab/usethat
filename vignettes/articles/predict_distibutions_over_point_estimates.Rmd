---
title: "Predict Distibutions over Point Estimate"
bibliography: [../../inst/REFERENCES.bib]
biblio-style: apalike
link-citations: yes
editor_options: 
  markdown: 
    wrap: 80
---

<!-- Compress random variables into distribution objects -->

```{r, include = FALSE}
source(file.path(usethis::proj_get(), "vignettes",  "_common.R"))
```

## Why should I care?

The ability to make correct inference on a random variable is influence by the
variable size. As the variable size gets bigger, our ability to make actionable
inference increases. For example, measuring people hight and taking the 95 hight
quantile allows automotive designers to decide on the space required between the
car seat and its ceiling.

Increasing random variable sizes requires us to devise a strategy for how to
represent them for further analysis, especially, in the case of multiple random
variable. For example, say we investigate the relationship of cars'
specifications and their fuel consumption. We start by taking *Mazda RX4* for a
ride, and measuring how many miles it covers before it consumes one gallon out
its 17 gallon fuel tank. The measurement could look something like this:

```{r, echo=TRUE}
Mazda_RX4 = c(22, 24, 18, 22, 18, 29, 26, 25, 23, 21, 22, 22, 17, 21, 19, 20, 24)
```

We do the same for the *Datsun 710* 12 gallon fuel tank:

```{r, echo=TRUE}
Datsun_710 = c(29, 27, 24, 26, 24, 23, 21, 25, 17, 18, 22, 25)
```

The question then is how to represent the two cars MPG in adjacent to their
following specifications:

```{r, results='hide'}
(
    cars_specs <- mtcars 
    %>% dplyr::select(-mpg) 
    %>% tibble::rownames_to_column("model")
    %>% dplyr::filter(model %in% c("Mazda RX4", "Datsun 710"))
)
```

```{r, echo=TRUE}
print(cars_specs)
```


There are two common ways:

1. Convert each random vector into a point estimator, such as median:

```{r, echo = TRUE}
cars <- data.frame(mpg = c(median(Mazda_RX4), median(Datsun_710)), cars_specs)
print(cars)
```

2. Add an `mpg` column, where each cell is a list contain all the information
available for a particular car

```{r, echo = TRUE}
cars <- data.frame(mpg = I(list(Mazda_RX4, Datsun_710)), cars_specs)
print(cars)
```

While representing both the 'mpg' measurements and the cars' specification in a
table is convenient for further analysis, there are some drawbacks to consider:

1. The first approach, which is also the most common one, exhibits information
loss when the variable is compressed into a scalar. As a result of the
information loss, there is no way to calculate other important statistics such
as the interquartile range (IQR) or mean.

2. The second approach can be memory/computational prohibitive, especially as
the number of samples in the random vector increases.

This article suggests a third approach that keeps important information and
bounds the size of information representation, regardless of the sample size.
This approach is based on statistical distributions.


<!-- using statistical distributions allows us to capture information in a succinct manner. -->
<!-- A variable of length n, can be compressed to a small set of parameters. For -->
<!-- example, the normal distribution, takes a variable of 100 numbers, and represent -->
<!-- it by two parameters, named mu ($\mu$) and sigma ($\sigma$), which correspond to -->
<!-- the mean and standard deviation of that variable.  -->


## Working with Distribution Objects

### What is a distribution object?

A **distribution object** preserves important statistical qualities of a random
variable in a succinct manner. Using the
[`distributional`](https://cran.r-project.org/web/packages/distributional/index.html)
R package, we can compress the following vector

```{r, echo=TRUE}
mpg_vec <- c(29, 27, 24, 26, 24, 23, 21, 25, 17, 18, 22, 25)
print(mpg_vec)
```

into a **distribution object** on length 1

```{r, echo=TRUE}
mpg_dist <- distributional::dist_normal(mu = mean(mpg_vec), sigma = sd(mpg_vec))
print(mpg_dist)
```

```{r, warning=TRUE}
warning("By using the normal distribution, a random variable of **any length** can be summarised by **two parameters**, the sample mean and standard deviation.")
```


A **distribution object** allows us to move a from `data.frame` with point
estimate column into a `data.frame` with a distribution column. For example,
instead of compressing the 'mpg' measurements of each car in the 'mtcars'
dataset into point estimations (the sample mean)

```{r, echo=FALSE}
data(mtcars, package = "datasets")
(
  mtcars
  %>% tibble::rownames_to_column("model")
  %>% tibble::as_tibble() 
  %>% dplyr::slice(c(1,3)) 
)
```

We can capture more information about the *mpg* measurements by using
**distribution objects**

```{r, echo=FALSE}
set.seed(1104)
(
  mtcars
  %>% tibble::rownames_to_column("model")
  %>% dplyr::rowwise() 
  %>% dplyr::mutate(mpg = distributional::dist_normal(mpg, round(runif(1, 1,3),1)))
  %>% dplyr::ungroup()
  %>% dplyr::slice(c(1,3))
)
```


### What operations can we perform on a distribution object?

Firstly, you can easily move from a **distribution object** into a point estimate by
using `distributional` functions:

```{r, echo=TRUE}
mpg_vec <- c(29, 27, 24, 26, 24, 23, 21, 25, 17, 18, 22, 25)
mpg_dist <- distributional::dist_normal(mu = mean(mpg_vec), sigma = sd(mpg_vec))

mean(mpg_vec); mean(mpg_dist)
median(mpg_vec); median(mpg_dist)
var(mpg_vec); distributional::variance(mpg_dist)

quantile(mpg_vec, p=0.75)[[1]]; quantile(mpg_dist, p=0.75)
min(mpg_vec); quantile(mpg_dist, p=0.01) # min approximation
max(mpg_vec); quantile(mpg_dist, p=0.99) # max approximation
```

Second, you can easily move from a **distribution object** into *Confidence Intervals* by using `distributional::hilo`:

```{r, echo=TRUE}
# z-confidence interval
c(
  mean(mpg_vec) - 1.96 * sd(mpg_vec)/sqrt(length(mpg_vec)),
  mean(mpg_vec) + 1.96 * sd(mpg_vec)/sqrt(length(mpg_vec))
) %>% round()

# quantile confidence interval
quantile(mpg_vec, probs = c(0.025, 0.975)) %>% round()

# distributional employs quantile confidence interval rather than z-confidence interval
distributional::hilo(mpg_dist, size = 95) %>% round()
```

```{r, warning=TRUE}
warning("Use `distributional::new_hilo` if you need a different type of confidence interval")
```

```{r}
z_ci <- distributional::new_hilo(
  lower = mean(mpg_vec) - 1.96 * sd(mpg_vec)/sqrt(length(mpg_vec)),
  upper = mean(mpg_vec) + 1.96 * sd(mpg_vec)/sqrt(length(mpg_vec)),
  size = 95
)

print(z_ci)
```

Finally, you can work with **distribution objects** stored in a data.frame as
you would do with any other atomic type:

```{r, echo=TRUE}
# Generate a data.frame with distribution objects
cars <- data.frame(
  model = c("Mazda RX4", "Datsun 710"),
  mpg = c(distributional::dist_normal(21, 2), distributional::dist_normal(22.8, 2.55))
)

# Extracting 'mpg' mean point estimation
cars %>% 
  dplyr::mutate(mpg = mean(mpg))

# Extracting 'mpg' 95% confidence interval
cars %>% 
  dplyr::mutate(CI = distributional::hilo(mpg, 95)) %>% 
  dplyr::mutate(CI_LB = CI$lower, CI_UB = CI$upper) %>% 
  dplyr::select(-CI)
```



```{r, message=TRUE}
message("See all available operations at [`distributional` package site](https://pkg.mitchelloharawild.com/distributional/).")
```



### How can we include distribution objects in our current workflow?

<!-- * distribution objects can be represented in one column of data.frame -->

<!-- * purrr/dplyr operations on a column (e.g. taking the mean as a point estimate) -->

## Generating Distribution Objects

text
